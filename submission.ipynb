{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QP2wDORnKxc-"
      },
      "outputs": [],
      "source": [
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import numpy as np\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "!pip install segmentation_models_pytorch\n",
        "import segmentation_models_pytorch as smp\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, models, transforms\n",
        "from torchvision.models import resnet18\n",
        "from torchvision.utils import draw_segmentation_masks\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import json\n",
        "\n",
        "from os import listdir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir final_0_5\n",
        "!unzip final_0_5.zip -d final_0_5"
      ],
      "metadata": {
        "id": "zNXT3jfzagUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir final_1_5\n",
        "!unzip final_1_5.zip -d final_1_5"
      ],
      "metadata": {
        "id": "41plw9Xyaiha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir final_5_8\n",
        "!unzip final_5_8.zip -d final_5_8"
      ],
      "metadata": {
        "id": "WiWE1CtjbC6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EyeDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Класс датасета, организующий загрузку и получение изображений и соответствующих разметок\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data_folder: str, transform = None):\n",
        "        self.class_ids = {\"vessel\": 1}\n",
        "\n",
        "        self.data_folder = data_folder\n",
        "        self.transform = transform\n",
        "        self._image_files = glob.glob(f\"{data_folder}/*.png\")\n",
        "\n",
        "        self._image_files = [i for i in self._image_files if glob.glob(i.replace(\"png\", \"geojson\"))]\n",
        "\n",
        "        # with open(\"image_files.txt\") as f:\n",
        "        #     files = f.read()\n",
        "        # files = files.split(', ')\n",
        "\n",
        "        # self._image_files = ['/content/train/' + file for file in files]\n",
        "        \n",
        "\n",
        "    @staticmethod\n",
        "    def read_image(path: str) -> np.ndarray:\n",
        "        image = cv2.imread(str(path), cv2.IMREAD_COLOR)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = np.array(image / 255, dtype=np.float32)\n",
        "        return image\n",
        "\n",
        "    @staticmethod \n",
        "    def parse_polygon(coordinates, image_size): \n",
        "        mask = np.zeros(image_size, dtype=np.int32) \n",
        "    \n",
        "        if len(coordinates) == 1: \n",
        "            points = [np.int32(coordinates)] \n",
        "            cv2.fillPoly(mask, points, 1) \n",
        "        else: \n",
        "            points = [np.int32([coordinates[0]])] \n",
        "            cv2.fillPoly(mask, points, 1) \n",
        "    \n",
        "            for polygon in coordinates[1:]:\n",
        "                points = [np.int32([polygon])] \n",
        "                cv2.fillPoly(mask, points, 0)\n",
        "        return mask\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_mask(shape: dict, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для парсинга фигур из geojson файла\n",
        "        \"\"\"\n",
        "        mask = np.zeros(image_size, dtype=np.int32)\n",
        "        coordinates = shape['coordinates']\n",
        "        if shape['type'] == 'MultiPolygon':\n",
        "            for polygon in coordinates:\n",
        "                mask |= EyeDataset.parse_polygon(polygon, image_size)\n",
        "        else:\n",
        "            mask |= EyeDataset.parse_polygon(coordinates, image_size)\n",
        "        # print(np.unique(mask))\n",
        "        return mask\n",
        "\n",
        "    def read_layout(self, path: str, image_size: tuple) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Метод для чтения geojson разметки и перевода в numpy маску\n",
        "        \"\"\"\n",
        "        with open(path, 'r', encoding='cp1251') as f:  # some files contain cyrillic letters, thus cp1251\n",
        "            json_contents = json.load(f)\n",
        "\n",
        "        num_channels = 1 + max(self.class_ids.values())\n",
        "        mask_channels = [np.zeros(image_size, dtype=np.float32) for _ in range(num_channels)]\n",
        "        mask = np.zeros(image_size, dtype=np.float32)\n",
        "\n",
        "        if type(json_contents) == dict and json_contents['type'] == 'FeatureCollection':\n",
        "            features = json_contents['features']\n",
        "        elif type(json_contents) == list:\n",
        "            features = json_contents\n",
        "        else:\n",
        "            features = [json_contents]\n",
        "\n",
        "        for shape in features:\n",
        "            channel_id = self.class_ids[\"vessel\"]\n",
        "            mask = self.parse_mask(shape['geometry'], image_size)\n",
        "            mask_channels[channel_id] = np.maximum(mask_channels[channel_id], mask)\n",
        "\n",
        "        mask_channels[0] = 1 - np.max(mask_channels[1:], axis=0)\n",
        "\n",
        "        return np.stack(mask_channels, axis=-1)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        # Достаём имя файла по индексу\n",
        "        image_path = self._image_files[idx]\n",
        "\n",
        "        # Получаем соответствующий файл разметки\n",
        "        json_path = image_path.replace(\"png\", \"geojson\")\n",
        "\n",
        "        image = self.read_image(image_path)\n",
        "\n",
        "        mask = self.read_layout(json_path, image.shape[:2])\n",
        "\n",
        "        sample = {'image': image,\n",
        "                  'mask': mask}\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._image_files)\n",
        "\n",
        "    # Метод для проверки состояния датасета\n",
        "    def make_report(self):\n",
        "      reports = []\n",
        "      if (not self.data_folder):\n",
        "        reports.append(\"Путь к датасету не указан\")\n",
        "      if (len(self._image_files) == 0):\n",
        "        reports.append(\"Изображения для распознавания не найдены\")\n",
        "      else:\n",
        "        reports.append(f\"Найдено {len(self._image_files)} изображений\")\n",
        "      cnt_images_without_masks = sum([1 - len(glob.glob(filepath.replace(\"png\", \"geojson\"))) for filepath in self._image_files])\n",
        "      if cnt_images_without_masks > 0:\n",
        "        reports.append(f\"Найдено {cnt_images_without_masks} изображений без разметки\")\n",
        "      else:\n",
        "        reports.append(f\"Для всех изображений есть файл разметки\")\n",
        "      return reports\n",
        "\n",
        "\n",
        "class DatasetPart(Dataset):\n",
        "    \"\"\"\n",
        "    Обертка над классом датасета для его разбиения на части\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset: Dataset,\n",
        "                 indices: np.ndarray,\n",
        "                 transform: A.Compose = None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx: int) -> dict:\n",
        "        sample = self.dataset[self.indices[idx]]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            sample = self.transform(**sample)\n",
        "\n",
        "        return sample\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.indices)"
      ],
      "metadata": {
        "id": "kufvbiJgLE9Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir voting_2"
      ],
      "metadata": {
        "id": "KS0baWA0LHqH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc"
      ],
      "metadata": {
        "id": "ig8nTaC-cbTR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import ToPILImage\n",
        "import copy\n",
        "\n",
        "for img_name in tqdm(listdir(\"/content/final_0_5\")):\n",
        "    image_0 = EyeDataset.read_image(\"/content/final_0_5/\" + img_name)\n",
        "    image_1 = EyeDataset.read_image(\"/content/final_1_5/\" + img_name)\n",
        "    image_2 = EyeDataset.read_image(\"/content/final_5_8/\" + img_name)\n",
        "    image = (image_0 * 0.7 + image_1 * 0.15 + image_2 * 0.15)\n",
        "    image = (image > 0.5).astype(np.uint8)\n",
        "    image *= 255\n",
        "    # pred_ask = np.reshape(pred_ask, (1, 1232, 1624))\n",
        "    mask = Image.fromarray(image)\n",
        "    # mask = mask.convert('L')\n",
        "    mask.save(\"voting_2/\" + img_name)\n",
        "    gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3aqVsHKoh53",
        "outputId": "bc878a8c-c5a3-4370-a3bb-ebae9b8c5c0a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 301/301 [01:41<00:00,  2.96it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd voting_2"
      ],
      "metadata": {
        "id": "lsLQs3rhjle1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r voting_2.zip *.png"
      ],
      "metadata": {
        "id": "NPEUU-rBLQgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv voting_2.zip ../voting_2.zip"
      ],
      "metadata": {
        "id": "CJFr2mkpdm5j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ky9RfJJuy11C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}